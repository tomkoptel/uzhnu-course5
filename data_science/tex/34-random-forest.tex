\chapter{Випадковий ліс дерев}\label{cha:random_forest_tree}
Дерева рішень залишають за вами важке рішення.
Глибоке дерево з великою кількістю рівнів перевантажиться, тому що кожне передбачення походить із історичних даних лише кількох будинків на його листі.
Але неглибоке дерево з невеликою кількістю листя буде працювати погано, оскільки воно не вловлює стільки відмінностей у вихідних даних.

Навіть найскладніші техніки моделювання сьогодні стикаються з проблемою між недооснащенням та переобладнанням.

У випадковому лісі використовується багато дерев, і він робить прогноз, усереднюючи прогнози кожного дерева компонентів.
Як правило, він має набагато кращу точність прогнозування, ніж одне дерево рішень, ця модель добре працює з параметрами за замовчуванням.

Випадковий ліс дерев демонструє значне ліпші результати порівняно з попереднім рішенням з одним деревом та помилкою у 250 000.

\begin{lstlisting}[style=light, language=Python,label={lst:vectorimg},caption=Random Forest Tree]
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.metrics import mean_absolute_error

        forest_model = RandomForestRegressor(random_state=1)
        forest_model.fit(train_X, train_y)
        melb_preds = forest_model.predict(val_X)
        print(mean_absolute_error(val_y, melb_preds))
        # 191669.7536453626
\end{lstlisting}
